import openai
import logging
from trialcurator.llm_client import LlmClient

logger = logging.getLogger(__name__)


class OpenaiClient(LlmClient):
    """
    A client for interacting with OpenAI's language models.

    This class wraps the OpenAI Python client and provides access to the
    OpenAI GPT models for generating text completions based on provided prompts.
    It extends the `LlmClient` abstract base class.
    """
    MODEL = "gpt-4o"

    def __init__(self, temperature, top_p, model=MODEL):
        """
        Initialize the OpenaiClient class with specific model and tuning parameters.

        Parameters:
            temperature (float): Sampling temperature, controlling randomness in generated responses.
            top_p (float): Nucleus sampling value, controlling diversity in generated responses.
            model (str): The name of the OpenAI model to use (defaults to "gpt-4o").
        """
        self.wrapped_client = openai.Client()
        self.temperature = temperature
        self.top_p = top_p
        self.model = model

    def llm_ask(self, prompt: str) -> str:
        """
        Send a prompt to the OpenAI language model and return the generated response.

        The method logs the prompt and the response at the INFO level for debugging.

        Parameters:
            prompt (str): The text prompt to send to the language model.

        Returns:
            str: The text response generated by the language model.
        """
        # log the prompt
        for line in prompt.splitlines():
            logging.info(f'prompt: {line}')

        completion = self.wrapped_client.chat.completions.create(
            model=self.model,
            temperature=self.temperature,
            top_p=self.top_p,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )

        # log the response
        response = completion.choices[0].message.content
        for line in response.splitlines():
            logging.info(f'response: {line}')

        return response
